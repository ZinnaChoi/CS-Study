# 데이터베이스

---

## 인덱스 (Index)

### 핵심 개념

인덱스는 검색 속도 향상을 위한 자료구조 (Full Scan O(n) → Index Scan O(log n))

---

### B+Tree를 사용하는 이유

**B-Tree vs B+Tree**
- B-Tree: 모든 노드에 (키 + 데이터) 저장
- B+Tree: Internal 노드는 키만, Leaf 노드는 (키 + 데이터 포인터)

**B+Tree 장점**
1. 범위 검색 최적화: Leaf 노드가 링크드 리스트로 연결
2. 캐싱 효율: Internal 노드에 키만 저장 → 더 많은 키를 메모리에 적재
3. 일관된 성능: 항상 Leaf까지 탐색 → depth 일정

---

### 클러스터드 vs 논클러스터드 인덱스

| 구분 | 클러스터드 | 논클러스터드 |
|------|-----------|-------------|
| 데이터 정렬 | 물리적 정렬 O | 정렬 X |
| 개수 | 테이블당 1개 (PK) | 여러 개 |
| 조회 단계 | 1단계 | 2단계 (인덱스 → PK) |
| 범위 검색 | 매우 빠름 | 보통 |

MySQL InnoDB: 모든 논클러스터드 인덱스가 PK 포함 → 커버링 인덱스 활용 가능

---

### 복합 인덱스 설계

**Left-Most Prefix Rule**
```sql
CREATE INDEX idx ON users (city, age, name);

-- 인덱스 사용
WHERE city = 'Seoul' AND age = 25

-- 인덱스 사용 X (city 생략)
WHERE age = 25
```

**컬럼 순서 결정 기준**
1. 동등 조건(=) → 범위 조건(>, BETWEEN)
2. 카디널리티 높은 것 우선
3. 자주 사용하는 조건 우선

---

### 커버링 인덱스

SELECT 컬럼이 모두 인덱스에 포함 → 테이블 접근 불필요

```sql
CREATE INDEX idx_covering ON orders (user_id, amount, created_at);
SELECT user_id, amount, created_at FROM orders WHERE user_id = 123;
-- Extra: Using index (커버링 인덱스)
```

---

### 특수 인덱스

- **GIN 인덱스**: 배열, JSONB, 전체 텍스트 검색에 최적화
- **부분 인덱스**: 조건을 만족하는 일부 행만 인덱싱 (`WHERE status = 'active'`)

---

### 트레이드오프

**장점**: 조회 O(log n), 정렬 비용 감소
**단점**: 쓰기 성능 저하 (INSERT 시 인덱스 모두 업데이트), 저장 공간 10-20% 증가

**인덱스 생성 기준**
- 생성: WHERE/JOIN에 자주 사용 + 카디널리티 높음 + 읽기 많음
- 비추천: 테이블 작음 + 카디널리티 낮음 + 쓰기 많음

---

### 면접 질문

**Q1. LIKE '%keyword%'는 왜 인덱스를 못 타나요?**
→ B+Tree는 왼쪽부터 정렬. `LIKE 'keyword%'`는 가능, `LIKE '%keyword'`는 불가.
해결: Full-Text Index 또는 Elasticsearch 도입

**Q2. 인덱스 있는데 안 쓰이는 이유는?**
→ 함수 사용 (`WHERE YEAR(date)`), 타입 불일치, LIKE 앞 와일드카드, 옵티마이저 판단

**Q3. 인덱스 확인 방법?**
→ `EXPLAIN` 사용
- `type: ref/const` (좋음) vs `type: ALL` (풀스캔, 나쁨)
- `key: 인덱스명` vs `key: NULL`
- `Extra: Using index` (커버링, 최고)

---

## 트랜잭션 (Transaction)

### 핵심 개념

트랜잭션: 하나의 논리적 작업 단위, All or Nothing

---

### ACID 속성

| 속성 | 의미 | 구현 방법 |
|------|------|----------|
| Atomicity | 모두 성공 or 모두 실패 | Undo Log |
| Consistency | 제약조건 항상 만족 | PK/FK/Check 제약 |
| Isolation | 트랜잭션 간 격리 | Lock, MVCC |
| Durability | COMMIT 후 영구 저장 | Redo Log, WAL |

---

### 격리 수준 (Isolation Level)

| 격리 수준 | Dirty Read | Non-Repeatable | Phantom Read | 기본값 |
|---------|------------|----------------|--------------|--------|
| READ UNCOMMITTED | O | O | O | - |
| READ COMMITTED | X | O | O | PostgreSQL |
| REPEATABLE READ | X | X | O* | MySQL |
| SERIALIZABLE | X | X | X | - |

*MySQL InnoDB는 MVCC로 Phantom Read도 대부분 방지

**부작용**
- Dirty Read: 커밋 안 된 데이터 읽음 → ROLLBACK 시 문제
- Non-Repeatable Read: 같은 데이터 조회했는데 값 변경됨
- Phantom Read: 같은 조건 조회했는데 행 개수 변경됨

---

### MVCC (Multi-Version Concurrency Control)

데이터 수정 시 이전 버전 보관 → 동시 접근 허용

**동작 원리**:
```
1. 트랜잭션 A: 데이터 읽기 (값: 100)
2. 트랜잭션 B: 데이터 수정 (100 → 200)
   → 새 버전 생성, 이전 버전(100) 보관 (Undo Log)
3. 트랜잭션 A: 다시 읽기 → 여전히 100 (Repeatable Read)
4. 트랜잭션 A 완료 → 이전 버전(100) 삭제 가능
```

**장점**:
- 읽기와 쓰기가 서로 블로킹 안 함
- 성능 향상 (락 경쟁 감소)

**MVCC 오버헤드** (롱 트랜잭션 문제):
```
정상: 트랜잭션 1초 → 이전 버전 1초 보관
문제: 트랜잭션 5시간 → 이전 버전 5시간 보관
→ Undo Log 계속 증가
→ 디스크/메모리 낭비
→ 쿼리 성능 저하
```

---

### Undo Log vs Redo Log

| 구분 | Undo Log | Redo Log |
|------|---------|----------|
| 목적 | 롤백, MVCC | 장애 복구 (Durability) |
| 내용 | 변경 전 값 | 변경 후 값 |
| 언제 사용 | ROLLBACK, 트랜잭션 진행 중 | 서버 재시작 시 |
| 삭제 시점 | 트랜잭션 완료 후 | 디스크 반영 후 |

**WAL (Write-Ahead Logging)**:
데이터 변경 전에 로그를 먼저 기록하는 원칙
1. Undo/Redo Log 먼저 기록 (빠름, 순차 쓰기)
2. 나중에 실제 데이터 페이지 수정 (느림, 랜덤 쓰기)

---

### Spring @Transactional 전파 (Propagation)

| Propagation | 동작 | 사용 사례 |
|-------------|------|----------|
| REQUIRED (기본) | 기존 있으면 참여, 없으면 생성 | 일반적인 경우 (95%) |
| REQUIRES_NEW | 항상 새 트랜잭션 생성 | 로그 저장, 독립 실행 |
| NESTED | Savepoint 생성 | 부분 롤백 |

**REQUIRED vs REQUIRES_NEW 차이**
```kotlin
// REQUIRED: 하나의 트랜잭션
@Transactional
fun outer() {
    save(user)
    inner()  // 같은 트랜잭션
}  // 둘 다 성공 or 둘 다 실패

// REQUIRES_NEW: 독립 트랜잭션
@Transactional
fun outer() {
    save(user)
    inner()  // 새 트랜잭션
}  // inner 실패해도 user는 커밋 가능

@Transactional(propagation = REQUIRES_NEW)
fun inner() { ... }
```

---

### readOnly = true

조회 메서드에 필수:
```kotlin
@Transactional(readOnly = true)
fun getUser(id: Long): User { ... }
```

**장점**
1. 하이버네이트 Dirty Checking 스킵 → 성능 향상
2. DB 최적화 (읽기 전용 실행, 락 최소화)
3. Read Replica로 라우팅 가능

---

### 면접 질문

**Q1. REQUIRES_NEW와 NESTED 차이는?**
→ REQUIRES_NEW: 완전 독립, 외부 실패해도 내부 커밋됨
→ NESTED: Savepoint, 외부 실패하면 내부도 롤백

**Q2. SAGA 패턴이란?**
→ 각 서비스는 로컬 트랜잭션만 사용
→ 실패 시 보상 트랜잭션으로 원복
→ 예: 주문 → 결제 → 배송 실패 시, 결제 취소 + 주문 취소

**Q3. 트랜잭션 아웃박스 패턴이란?**
→ DB 변경과 이벤트 발행을 원자적으로 처리하는 패턴
→ 동작: DB 저장 + Outbox 테이블에 이벤트 저장 (같은 트랜잭션) → 별도 프로세스가 Outbox 읽어서 메시지 발행
→ 장점: DB와 메시지 발행의 정합성 보장

---

## 락 (Lock) & 동시성

### 핵심 개념

락: 동시 수정 시 데이터 정합성 보장

---

### 락의 종류

| 구분 | Shared Lock (S) | Exclusive Lock (X) |
|------|-----------------|-------------------|
| 용도 | 읽기 | 쓰기 |
| 동시 접근 | 여러 트랜잭션 가능 | 1개만 |
| 호환 | S Lock끼리 O | 모두 X |
| SQL | `LOCK IN SHARE MODE` | `FOR UPDATE` |

---

### Optimistic Lock vs Pessimistic Lock

| 구분 | 낙관적 락 | 비관적 락 |
|------|----------|----------|
| 가정 | 충돌 드물다 | 충돌 많다 |
| 락 시점 | UPDATE 시 | SELECT 시 |
| 구현 | `@Version` | `FOR UPDATE` |
| 충돌 처리 | 예외 발생 → 재시도 | 대기 → 순차 처리 |
| 성능 | 높음 | 낮음 |
| 데드락 | 없음 | 가능 |
| 사용 사례 | 게시글 조회수, 통계 | 재고 차감, 좌석 예매 |

**선택 기준**
- 충돌 자주? → 비관적 / 드물다 → 낙관적
- 정확성 중요? → 비관적
- 성능 중요? → 낙관적

---

### Phantom Read와 Next-Key Lock

**Phantom Read**: 같은 쿼리 2번 실행 → 행 개수 변경

```sql
-- 트랜잭션 A (Repeatable Read)
SELECT * FROM users WHERE age BETWEEN 20 AND 30;  -- 5건
-- (트랜잭션 B가 age=25 INSERT)
SELECT * FROM users WHERE age BETWEEN 20 AND 30;  -- 6건 (Phantom!)
```

**InnoDB 3가지 락**:

| 락 종류 | 설명 | 예시 |
|---------|------|------|
| Record Lock | 인덱스 레코드 잠금 | id=10 락 |
| Gap Lock | 레코드 사이 간격 잠금 | id 10~20 사이 간격 락 |
| Next-Key Lock | Record + Gap | id=10 + 10~20 간격 동시 락 |

**Next-Key Lock 동작** (Repeatable Read 기본):
```
테이블: id = 10, 20, 30

SELECT * FROM users WHERE id >= 10 AND id < 30 FOR UPDATE;

락 범위:
- Record Lock: id=10, id=20
- Gap Lock: (10~20), (20~30)
→ Next-Key Lock: 10~30 전체 범위

결과: 다른 트랜잭션이 id=15 INSERT 불가 → Phantom Read 방지
```

**주의사항**:
- 인덱스 없으면 전체 테이블 잠금
- Next-Key Lock은 범위가 넓어서 동시성 저하
- 불필요한 Gap Lock → 데드락 위험 증가

---

### Deadlock 해결

**발생 원인**: 트랜잭션 A와 B가 서로 가진 락을 대기

**해결 방법**
1. 락 순서 일관화 (가장 효과적): 모든 트랜잭션이 같은 순서로 락 획득
2. 락 타임아웃: 5초 대기 후 자동 롤백
3. 트랜잭션 최소화: 락 보유 시간 단축

MySQL 자동 해결: 데드락 감지 시 한 트랜잭션 자동 ROLLBACK → 애플리케이션에서 재시도

---

### 면접 질문

**Q1. 낙관적 락 실패 시 재시도 전략은?**
```kotlin
@Retryable(
    value = [OptimisticLockException::class],
    maxAttempts = 3,
    backoff = Backoff(delay = 100)
)
fun updateProduct(id: Long, qty: Int) { ... }
```

**Q2. SELECT FOR UPDATE를 인덱스 없는 컬럼에 사용하면?**
→ 전체 테이블 스캔 → 모든 레코드 락 → 다른 트랜잭션 완전 차단
→ 해결: WHERE 절 컬럼에 인덱스 추가

---

## 쿼리 최적화

### SELECT 쿼리 실행 플로우

```
애플리케이션 → Connection Pool → DB 서버
                                   ↓
                        [1] Parser (구문 분석)
                                   ↓
                        [2] Optimizer (실행 계획 수립)
                                   ↓
                        [3] Executor (실행 엔진)
                                   ↓
                        [4] Storage Engine (InnoDB)
                                   ↓
                        [5] Buffer Pool (메모리 캐시)
                          ↓ YES        ↓ NO
                        메모리 반환   Disk I/O
                                   ↓
                              결과 반환
```

**단계별 설명**:
1. **Parser**: SQL 문법 검사 + 파싱 트리 생성
2. **Optimizer**: 통계 정보 확인, 여러 실행 계획 비교 후 비용 계산, 최적 실행 계획 선택
3. **Executor**: Optimizer가 정한 계획대로 실행
4. **Storage Engine (InnoDB)**: 실제 데이터 저장/조회, 트랜잭션, Lock, MVCC 처리
5. **Buffer Pool**: InnoDB의 메모리 캐시, 데이터가 메모리에 있으면 바로 반환

---

### EXPLAIN 주요 컬럼

**type (접근 방법)**: 성능 순서
```
system > const > eq_ref > ref > range > index > ALL
         (PK 단일)  (JOIN PK)  (인덱스)  (범위)  (인덱스풀)  (풀스캔)
```

**key**: 사용된 인덱스 (NULL이면 풀스캔)

**rows**: 예상 조회 행 수 (적을수록 좋음)

**Extra**
- `Using index`: 커버링 인덱스 (최고)
- `Using filesort`: 정렬 추가 작업 (인덱스 추가 고려)
- `Using temporary`: 임시 테이블 사용 (비효율)

---

### 쿼리 최적화 팁

**COUNT(\*) vs COUNT(column)**
```sql
-- 빠름 (인덱스 활용)
SELECT COUNT(*) FROM users;

-- 느림 (컬럼 값 확인)
SELECT COUNT(email) FROM users;

-- 존재 여부는 EXISTS
SELECT EXISTS(SELECT 1 FROM users WHERE id = 10);
```

**인덱스 못 타는 경우**
```sql
-- 함수 사용 X
WHERE YEAR(created_at) = 2024

-- 범위 조건 O
WHERE created_at BETWEEN '2024-01-01' AND '2024-12-31'
```

---

## 리플리케이션

### Master-Slave 구조

```
[Master DB] (쓰기 전용)
    ↓ 복제 (Binlog)
┌───┴───┐
[Slave 1] [Slave 2] (읽기 전용)
```

**동작 방식**
1. Master에 쓰기 → Binlog 기록
2. Slave가 Binlog 읽어서 복제
3. 읽기는 Slave에서 수행

---

### Replication Lag (복제 지연)

**문제**: 비동기 복제 → Master 쓰기 후 즉시 Slave 조회하면 데이터 없을 수 있음

**해결**
```kotlin
// 쓰기 직후 읽기는 Master
@Transactional(readOnly = false)
fun createUser(user: User): User {
    val saved = userRepository.save(user)  // Master
    return userRepository.findById(saved.id)  // Master
}

// 일반 조회는 Slave
@Transactional(readOnly = true)
fun getUser(id: Long): User {
    return userRepository.findById(id)  // Slave
}
```

---

## Connection Pool

### 핵심 개념

Connection Pool: DB 연결을 미리 생성해서 재사용 → 성능 향상

**왜 필요한가?**
- Connection 생성 비용 높음 (100ms)
- Pool 사용 시 즉시 획득 (1ms)

---

### HikariCP Pool Size 설정

초기 설정: CPU 코어 수 x 2
부하 테스트 → 모니터링 → 튜닝

**모니터링 지표**
- active (사용 중)
- idle (유휴)
- waiting (대기 중)

---

### 타임아웃 종류

| 타임아웃 | 레벨 | 설명 | 목적 |
|----------|------|------|------|
| idle-timeout | 애플리케이션 (HikariCP) | 놀고 있는 커넥션 제거 시점 | 애플리케이션 리소스 절약 |
| max-lifetime | 애플리케이션 (HikariCP) | 커넥션의 최대 수명 | 커넥션 품질 관리 |
| wait_timeout | DB 서버 (MySQL) | DB가 놀고 있는 커넥션 강제 종료 | DB 서버 리소스 보호 |

> 주의: wait_timeout까지 가면 SQLException 발생하므로 애플리케이션 레벨에서 미리 관리 필요

---

### 면접 질문

**Q. Connection Pool Size 설정 방법은?**
1. 초기: CPU 코어 수 x 2
2. JMeter 부하 테스트
3. 모니터링: active, idle, waiting
4. 튜닝: Connection 부족 시 증가, DB CPU 높으면 감소

---

## CQRS 패턴

### 핵심 개념

CQRS (Command Query Responsibility Segregation): 읽기(Query)와 쓰기(Command) 책임을 분리하는 아키텍처 패턴

### 기본 구조

```
[Command (쓰기)]          [Query (읽기)]
       ↓                        ↓
  [Write DB]  ----동기화--->  [Read DB]
   (정규화)                  (비정규화)
```

**핵심 아이디어**
- Command: 데이터 변경 (INSERT, UPDATE, DELETE) → Write DB
- Query: 데이터 조회 (SELECT) → Read DB
- 두 DB는 비동기로 동기화

---

### 장점 vs 단점

| 구분 | 내용 |
|------|------|
| 장점 | 읽기/쓰기 독립적 확장 가능, 읽기 DB를 조회에 최적화 (비정규화, 집계 테이블), 쓰기 성능과 읽기 성능 분리 |
| 단점 | 구현 복잡도 증가, 데이터 정합성 이슈 (Eventual Consistency), 스토리지 2배 필요, 동기화 지연 처리 필요 |

---

### 동기화 방식

**1) CDC (Change Data Capture)**
- DB의 Binlog를 읽어서 자동 동기화
- 도구: Debezium, Maxwell

**2) 이벤트 기반**
```kotlin
@Transactional
fun createOrder(order: Order) {
    orderRepository.save(order)  // Write DB
    eventPublisher.publish(OrderCreatedEvent(order))  // Kafka/RabbitMQ
}

// Consumer
fun onOrderCreated(event: OrderCreatedEvent) {
    readOrderRepository.save(event.toReadModel())  // Read DB
}
```

**3) Batch 동기화**
- 주기적으로 Write DB → Read DB 동기화
- 실시간성은 떨어지지만 구현 단순

---

### 언제 사용하나?

**사용하는 경우**
- 읽기와 쓰기 비율 차이가 큰 경우 (예: 읽기 90%, 쓰기 10%)
- 복잡한 조회 쿼리가 많은 경우 (집계, JOIN 다수)
- 읽기/쓰기를 독립적으로 확장해야 하는 경우

**사용하지 않는 경우**
- 소규모 서비스 (오버 엔지니어링)
- 실시간 정합성이 필수인 경우

---

### 면접 질문

**Q1. CQRS와 Read Replica의 차이는?**
→ Read Replica: 같은 스키마, 자동 복제, 읽기만 분산
→ CQRS: 다른 스키마 가능, 읽기 최적화 (비정규화), 수동 동기화

**Q2. Eventual Consistency는 어떻게 처리하나요?**
→ 쓰기 직후 읽기는 Write DB에서 조회
→ 일반 조회는 Read DB 사용
→ UI에 "데이터 동기화 중" 표시

---

## 대용량 데이터 처리

### 핵심 개념

대용량 데이터 처리: 수백만~수억 건의 데이터를 효율적으로 조회/저장하는 전략

---

### 대용량 조회 전략

#### 1) 인덱스 활용

**커버링 인덱스 (최고의 성능)**:
```sql
-- 테이블 접근 필요 X
CREATE INDEX idx_covering ON users (user_id, name, email);
SELECT user_id, name, email FROM users WHERE user_id > 1000000 LIMIT 1000;
-- Extra: Using index (테이블 접근 없음)
```

**복합 인덱스 활용**:
```sql
-- 자주 조회하는 패턴
SELECT * FROM orders
WHERE user_id = ? AND status = 'PAID'
ORDER BY created_at DESC;

-- 최적 인덱스
CREATE INDEX idx_user_status_created ON orders (user_id, status, created_at);
-- Left-Most Prefix: user_id → status → created_at 순서 중요
```

---

#### 2) 페이지네이션

**Offset vs Cursor 비교**:

| 방식 | Offset | Cursor |
|------|--------|--------|
| 쿼리 | `LIMIT 100 OFFSET 1000000` | `WHERE id > 1000000 LIMIT 100` |
| 성능 | 느림 (오프셋만큼 스캔) | 빠름 (인덱스 Seek) |
| 페이지 | 1, 2, 3 페이지 가능 | 다음/이전만 가능 |
| 사용 | 관리자 화면 | 무한 스크롤, 피드 |

**Cursor 방식 (빠름)**:
```sql
-- 첫 페이지
SELECT * FROM orders WHERE id > 0 ORDER BY id LIMIT 100;
-- 마지막 id: 100

-- 다음 페이지
SELECT * FROM orders WHERE id > 100 ORDER BY id LIMIT 100;
-- 성능: 일정하게 0.01초
```

**실무 구현 (Spring Data JPA)**:
```kotlin
interface OrderRepository : JpaRepository<Order, Long> {
    // Cursor 기반 페이지네이션
    fun findTop100ByIdGreaterThanOrderById(lastId: Long): List<Order>
}

// 사용
var lastId = 0L
while (true) {
    val orders = orderRepository.findTop100ByIdGreaterThanOrderById(lastId)
    if (orders.isEmpty()) break

    process(orders)
    lastId = orders.last().id
}
```

---

#### 3) Streaming & Chunk 처리

**문제**: 100만 건 조회 시 메모리 부족 (OOM)

**해결: Chunk 단위 처리** (권장):
```kotlin
fun processAllOrders() {
    var lastId = 0L

    while (true) {
        val orders = processChunk(lastId)
        if (orders.isEmpty()) break
        lastId = orders.last().id
    }
}

@Transactional
fun processChunk(lastId: Long): List<Order> {
    val orders = orderRepository.findTop1000ByIdGreaterThanOrderById(lastId)
    orders.forEach { process(it) }
    return orders
}
// 장점: 1000건씩 커밋 → 메모리 안전, 실패 시 재시작 가능
```

---

#### 4) DTO Projection (메모리 최적화)

**문제**: 엔티티 전체 조회 → 불필요한 컬럼까지 메모리 적재 → OOM

**비교**:
```kotlin
// 엔티티 전체 (모든 컬럼 + 연관관계)
@Query("SELECT u FROM User u")
fun findAll(): List<User>
// 100만 건 x 1KB = 1GB 메모리 사용

// DTO로 필요한 컬럼만
data class UserDto(val id: Long, val name: String)

@Query("SELECT new com.example.UserDto(u.id, u.name) FROM User u")
fun findAllDto(): List<UserDto>
// 100만 건 x 100B = 100MB 메모리 (10배 절약)
```

**DTO Projection 종류**:

| 방식 | 코드 | 특징 |
|------|------|------|
| Interface Projection | `interface UserDto { fun getName(): String }` | 간단, Lazy 로딩 가능 |
| Class Projection | `data class UserDto(val id: Long, val name: String)` | 명시적, 타입 안전 |
| Native Query | `@Query(nativeQuery = true)` | 복잡한 쿼리, 성능 최고 |

**언제 사용?**
- 대량 조회 (수만 건 이상)
- 필요한 컬럼 < 전체 컬럼의 50%
- 연관관계 조회 불필요
- 조회 후 수정 불필요 (수정 필요하면 엔티티로 조회)

---

### 대용량 쓰기 전략

#### 1) Batch Insert (JDBC Batch)

**문제**: 10만 건 INSERT → 10만 번 DB 왕복 (100초)

**해결: JPA Batch Insert**:
```yaml
spring:
  jpa:
    properties:
      hibernate:
        jdbc:
          batch_size: 1000  # 1000건씩 배치
        order_inserts: true
        order_updates: true
```

```kotlin
@Transactional
fun saveAll(orders: List<Order>) {
    orders.chunked(1000).forEach { chunk ->
        orderRepository.saveAll(chunk)
        entityManager.flush()
        entityManager.clear()  // 메모리 해제
    }
}
// 성능: 100초 → 10초 (10배 향상)
```

**JDBC Batch (더 빠름)**:
```kotlin
fun batchInsert(orders: List<Order>) {
    val sql = "INSERT INTO orders (user_id, amount) VALUES (?, ?)"

    jdbcTemplate.batchUpdate(sql, orders, 1000) { ps, order ->
        ps.setLong(1, order.userId)
        ps.setBigDecimal(2, order.amount)
    }
}
// 성능: JPA보다 2~3배 빠름
```

---

#### 2) Bulk Insert (LOAD DATA INFILE)

**최고 성능**: CSV 파일 → DB 직접 로드

```sql
-- MySQL
LOAD DATA INFILE '/tmp/orders.csv'
INTO TABLE orders
FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n'
(user_id, amount, created_at);

-- 성능: 100만 건 → 5초 (JDBC Batch의 10배)
```

**사용 케이스**:
- 데이터 마이그레이션
- 대량 초기 데이터 로드
- 배치 처리 결과 저장

---

#### 3) 비동기 처리 (Message Queue)

**문제**: 100만 건 동기 INSERT → 서버 블로킹 (30분)

**해결: Kafka/RabbitMQ로 비동기 처리**:
```kotlin
// 1. 메시지 발행 (빠름, 1초)
fun publishOrders(orders: List<Order>) {
    orders.forEach { order ->
        kafkaTemplate.send("order-topic", order)
    }
}

// 2. Consumer에서 배치 처리
@KafkaListener(topics = ["order-topic"])
fun consumeOrders(orders: List<Order>) {
    orderRepository.saveAll(orders)  // 1000건씩 배치
}
```

---

### 인덱스 추가 전략 (운영 환경)

**문제**: 1억 건 테이블에 인덱스 추가 → 30분 소요 → 서비스 영향

#### 1) Online DDL (MySQL 5.6+)

```sql
CREATE INDEX idx_user_id ON orders(user_id) ALGORITHM=INPLACE, LOCK=NONE;
-- ALGORITHM=INPLACE: 테이블 복사 없이 추가
-- LOCK=NONE: SELECT/INSERT/UPDATE 계속 가능
```

**주의사항**:
- DDL 진행 중에도 읽기/쓰기 가능
- 하지만 CPU/디스크 I/O 사용량 증가 → 성능 저하
- 트래픽 낮을 때 실행 권장 (새벽 3시)

---

#### 2) pt-online-schema-change (Percona Toolkit)

**더 안전한 방법** (대형 서비스):
```bash
pt-online-schema-change \
  --alter "ADD INDEX idx_user_id (user_id)" \
  --execute h=localhost,D=mydb,t=orders
```

**동작 원리**:
```
1. 새 테이블 생성 (orders_new)
2. 트리거 생성 (변경사항 실시간 복제)
3. 기존 데이터 복사 (Chunk 단위)
4. 테이블 교체 (원자적 RENAME)
5. 기존 테이블 삭제

장점:
- 서비스 영향 최소화 (락 거의 없음)
- Chunk 단위 복사로 부하 분산
- 실패 시 롤백 가능
```

---

#### 3) 인덱스 추가 절차 (실무)

```
1. 개발 환경 테스트:
   - 동일한 데이터량으로 테스트 (1억 건)
   - 소요 시간 측정 (30분)
   - 실행 계획 확인 (EXPLAIN)

2. 운영 환경 적용:
   - 트래픽 낮은 시간 (새벽 3시)
   - DB Slave에서 먼저 추가
   - Master에 적용 전 Slave 성능 확인

3. 모니터링:
   - CPU/디스크 I/O 사용률
   - Slow Query 증가 여부
   - Replication Lag

4. 인덱스 효과 확인:
   - EXPLAIN으로 인덱스 사용 확인
   - 쿼리 실행 시간 비교
   - 사용 안 하면 DROP
```

---

### 확장 전략

#### 1) 파티셔닝 (Partitioning)

**개념**: 하나의 큰 테이블을 여러 파티션으로 분할

**종류**:

| 타입 | 기준 | 사용 사례 |
|------|------|----------|
| Range | 범위 (날짜, 숫자) | 로그, 주문 (월별) |
| Hash | 해시 함수 | 고른 분산 (user_id) |
| List | 값 목록 | 지역별 (서울, 부산) |

**Range Partitioning** (가장 많이 사용):
```sql
CREATE TABLE orders (
    id BIGINT,
    user_id BIGINT,
    created_at DATE,
    ...
) PARTITION BY RANGE (YEAR(created_at)) (
    PARTITION p2022 VALUES LESS THAN (2023),
    PARTITION p2023 VALUES LESS THAN (2024),
    PARTITION p2024 VALUES LESS THAN (2025),
    PARTITION p_future VALUES LESS THAN MAXVALUE
);
```

**장점**:
```sql
-- 2023년 데이터만 조회 → p2023 파티션만 스캔
SELECT * FROM orders WHERE created_at >= '2023-01-01' AND created_at < '2024-01-01';
-- 성능: 전체 스캔 10초 → 파티션 스캔 1초

-- 오래된 파티션 삭제 (빠름)
ALTER TABLE orders DROP PARTITION p2022;
-- 성능: DELETE 10분 → DROP PARTITION 1초
```

**주의사항**:
- 파티션 키는 모든 쿼리에 포함되어야 효과적
- 파티션 키 없는 쿼리 → 전체 파티션 스캔

---

#### 2) 샤딩 (Sharding)

**개념**: 데이터를 여러 DB 서버로 분산 (Horizontal Partitioning)

**방식**:
```
Modulo Sharding:
- user_id % 4 = 0 → DB0
- user_id % 4 = 1 → DB1
- user_id % 4 = 2 → DB2
- user_id % 4 = 3 → DB3
```

**장점**:
- 쓰기 성능 향상 (여러 DB 동시 쓰기)
- DB 크기 제한 극복 (1TB → 250GB x 4)

**단점**:
- JOIN 불가 (다른 DB)
- 트랜잭션 복잡 (분산 트랜잭션)
- 샤드 재분배 어려움 (4 → 8개)

**언제 사용?**
- 데이터 10TB 이상
- 쓰기 TPS 10,000 이상
- JOIN 적음
- 트랜잭션 단순

---

#### 3) 아카이빙 (Archiving)

**개념**: 오래된 데이터를 별도 테이블/DB로 이동

**전략**:
```sql
-- 1. 아카이브 테이블 생성
CREATE TABLE orders_archive LIKE orders;

-- 2. 1년 지난 데이터 이동
INSERT INTO orders_archive
SELECT * FROM orders WHERE created_at < '2023-01-01';

-- 3. 원본 삭제 (Chunk 단위)
DELETE FROM orders WHERE id IN (
    SELECT id FROM orders WHERE created_at < '2023-01-01' LIMIT 10000
);

-- 4. 반복 (전체 이동까지)
```

**장점**:
- 메인 테이블 크기 감소 → 쿼리 빨라짐
- 백업/복구 시간 단축

---

### 면접 질문

**Q1. 1억 건 데이터를 어떻게 조회하나요?**

```
상황에 따라 다릅니다:

1. 전체 조회 필요 (배치):
   - Cursor 기반 페이지네이션 (WHERE id > ? LIMIT 1000)
   - Chunk 단위 처리 (1000건씩 커밋)
   - DTO Projection (필요한 컬럼만 조회 → 메모리 10배 절약)
   - 트랜잭션 짧게 유지 → 커넥션 풀 고갈 방지

2. 사용자 조회 (API):
   - 커버링 인덱스로 테이블 접근 최소화
   - Cursor 페이지네이션 (무한 스크롤)
   - DTO Projection (엔티티 1KB → DTO 100B)
   - Redis 캐싱

핵심: 인덱스 + 페이지네이션 + DTO Projection + 메모리 관리
```

---

**Q2. 초당 1만 건 INSERT를 어떻게 처리하나요?**

```
4단계 전략으로 처리합니다:

1. Batch Insert (기본):
   - JDBC Batch로 1000건씩 묶어서 INSERT
   - 성능: 10배 향상

2. 비동기 처리 (중요):
   - Kafka로 비동기 수집
   - Consumer에서 배치 처리
   - 서버 블로킹 방지

3. 파티셔닝:
   - 날짜별 파티셔닝 → 병렬 쓰기

4. 샤딩 (최후):
   - 10TB 초과 시 DB 분산
   - user_id % 4로 4개 DB에 분산

실무: Kafka + Batch Insert 조합이 가장 효과적
```

---

**Q3. 파티셔닝과 샤딩의 차이는?**

```
핵심 차이: 같은 DB vs 다른 DB

1. 파티셔닝 (Partitioning):
   하나의 DB 서버 안에서 큰 테이블을 여러 파티션으로 분할

   [MySQL Server]
     └─ orders 테이블
         ├─ p2023 (2023년 데이터)
         ├─ p2024 (2024년 데이터)
         └─ p2025 (2025년 데이터)

   - WHERE created_at >= '2024-01-01' → p2024 파티션만 스캔
   - JOIN 가능 (같은 DB)
   - 확장성 제한 (한 서버)

2. 샤딩 (Sharding):
   데이터를 여러 DB 서버로 분산

   [DB0] user_id % 4 = 0 → users (id: 4, 8, 12...)
   [DB1] user_id % 4 = 1 → users (id: 1, 5, 9...)
   [DB2] user_id % 4 = 2 → users (id: 2, 6, 10...)
   [DB3] user_id % 4 = 3 → users (id: 3, 7, 11...)

   - JOIN 불가 (다른 서버)
   - 분산 트랜잭션 필요 (복잡)
   - 확장성 무한 (서버 추가)

| 구분 | 파티셔닝 | 샤딩 |
|------|---------|------|
| 범위 | 테이블 분할 (같은 DB) | DB 분산 (다른 서버) |
| JOIN | 가능 | 불가 |
| 트랜잭션 | 가능 | 복잡 (분산) |
| 확장성 | 제한적 (한 서버) | 무한 (서버 추가) |
| 사용 시기 | 수억 건 | 10TB 이상 |

실무 순서:
1. Read Replica (읽기 분산)
2. 파티셔닝 (테이블 분할)
3. CQRS (읽기/쓰기 분리)
4. 샤딩 (최후의 수단, 복잡도 ↑)
```

---

## Redis (Remote Dictionary Server)

### 핵심 개념

- 인메모리 Key-Value NoSQL 데이터베이스
- 메모리 기반으로 매우 빠른 성능 (O(1) 시간 복잡도)
- 싱글 스레드 → 동시성 이슈 없음

**주요 사용처**
- 캐싱 (조회 성능 향상)
- 세션/인증 관리 (Refresh Token 저장)
- 재고 관리, 좋아요 수 등 동시성 제어
- 실시간 순위/랭킹

---

### 자료구조 & 활용 사례

| 자료구조 | 특징 | 활용 예시 | 주요 명령어 |
|---------|------|----------|------------|
| String | 가장 기본적인 key-value | 캐싱, 토큰 저장, 조회수 | SET, GET, INCR, DECR |
| List | Deque (양방향 큐) | 최근 방문 페이지 (중복 허용) | LPUSH, RPUSH, LRANGE |
| Set | 중복X, 순서X | 좋아요 (중복 방지), 일 방문자 수 | SADD, SMEMBERS, SCARD |
| ZSet | 중복X, score 기준 정렬 | 최근 본 상품(중복X), 실시간 랭킹 | ZADD, ZRANGE, ZREVRANGE |
| Hash | value가 Map 형태 | 자주 변경되는 객체 캐싱 | HSET, HGET, HGETALL |

**면접 포인트**
- String vs Hash: JSON 문자열 전체 수정 vs 특정 필드만 수정 → Hash가 유리
- List vs ZSet: 중복 허용 vs 중복 제거 + 정렬

---

### TTL (Time To Live)

```shell
SET key value EX 10    # 10초 후 자동 삭제
EXPIRE key 20          # 기존 키에 20초 TTL 설정
TTL key                # 남은 시간 조회
```

---

### 서버 구성

**Replication (복제)**
- Master(쓰기) + Slave(읽기) 구조
- 읽기 성능 향상, 하지만 용량 한계 존재 (마스터 메모리 제한)

**Sharding (샤딩)**
- 데이터를 여러 서버에 분산 저장
- 용량 한계 극복 (100GB → 10대 서버에 10GB씩)

**Cluster (클러스터)**
- 샤딩 + 고가용성 자동 관리
- 16,384개 Hash Slot 사용
- 마스터 장애 시 슬레이브가 자동 승격
- 서버 추가 시 슬롯 자동 재분배

| 구분 | Replication | Cluster |
|------|------------|---------|
| 데이터 저장 | 전체 복제 | 분산 샤딩 |
| 용량 한계 | Master 메모리 크기 | 노드 추가로 확장 |
| 목적 | 읽기 성능 + HA | 데이터 분산 + 확장 |
| Failover | Sentinel 필요 | 자동 |
| 최소 노드 | 1 Master + 1 Slave | 3 Master + 3 Slave |

---

### 싱글 스레드 동작 원리

**Redis는 싱글 스레드인데 어떻게 동시에 여러 요청을 처리할까?**

핵심: I/O Multiplexing + Event Loop

Redis는 스레드가 1개지만, 여러 클라이언트 연결을 동시에 감시하고 준비된 요청을 빠르게 순차 처리합니다.

**동작 방식**
```
[클라이언트 A] GET user:1     ──┐
[클라이언트 B] INCR counter   ──┤→ [epoll이 감시] → 준비된 요청 감지
[클라이언트 C] SET key value  ──┘

↓

[Redis 싱글 스레드 Event Loop]
1. A의 GET 처리 (0.01ms) → 응답
2. B의 INCR 처리 (0.01ms) → 응답
3. C의 SET 처리 (0.01ms) → 응답

총 소요: 0.03ms
```

**싱글 스레드의 장점**
1. 락 오버헤드 없음: 멀티 스레드는 Lock 필요 → 성능 저하
2. 컨텍스트 스위칭 없음: 스레드 전환 없이 계속 실행
3. Atomic 보장: `INCR` 같은 명령어가 중간에 끊기지 않고 완전히 실행됨

---

### 분산 락

**분산 락이란?**
여러 서버(인스턴스)가 동시에 같은 자원에 접근할 때, 한 번에 하나의 서버만 작업할 수 있도록 제어하는 메커니즘

**왜 필요한가?**
- 재고 차감 (동시 구매)
- 결제 처리 (중복 결제 방지)
- 쿠폰 발급 (선착순 제한)
- 좌석 예약 (중복 예약 방지)

**기본 구현: SET NX EX**
```shell
SET lock:resource value NX EX 10
```
- `NX`: 키가 없을 때만 설정 → Lock 획득
- `EX 10`: 10초 TTL → 데드락 방지

**Redisson: Lua 스크립트 기반 분산 락**

Redisson 3가지 핵심 기능:
1. Lua 스크립트 자동 사용: Lock 획득 시 UUID 자동 생성, 해제 시 UUID 검증 후 삭제
2. Watch Dog (자동 TTL 갱신): 작업이 오래 걸리면 TTL 자동 연장 (30초마다)
3. 재시도 로직 내장: `tryLock(10, 5, SECONDS)` - 10초 재시도, 5초 TTL

---

### Redis 영속성 (Persistence)

**RDB (Redis Database) - 스냅샷**
- 개념: 특정 시점의 메모리 전체를 디스크에 저장
- 장점: 파일 크기 작음, 복구 속도 빠름
- 단점: 데이터 유실 가능 (마지막 스냅샷 이후 변경 손실)

**AOF (Append Only File) - 명령어 로그**
- 개념: 모든 쓰기 명령어를 로그 파일에 추가 기록
- 장점: 데이터 유실 최소화 (everysec 사용 시 최대 1초치만 손실)
- 단점: 파일 크기 큼, 복구 속도 느림

| 구분 | RDB | AOF |
|-----|-----|-----|
| 속도 | 빠름 | 느림 |
| 파일 크기 | 작음 | 큼 |
| 데이터 유실 | 마지막 스냅샷 이후 손실 | 최대 1초치 손실 |
| 복구 속도 | 빠름 | 느림 |
| 용도 | 백업, 재해 복구 | 데이터 보존 중요 |

---

### 면접 질문

**Q1. Redis는 왜 빠른가?**
- 인메모리 (디스크 I/O 없음)
- Key-Value 구조 (해시 테이블 O(1))
- 싱글 스레드 (락 오버헤드 없음)

**Q2. 싱글 스레드인데 어떻게 동시 처리?**
- Event Loop + I/O Multiplexing
- 명령어 하나하나가 atomic하게 처리됨

**Q3. 동시성 제어가 필요한 상황에서 Redis를 왜 쓰나?**
- RDB: SELECT → UPDATE +1 (동시 요청 시 데이터 꼬임)
- Redis: INCR 명령어 자체가 atomic

**Q4. Redis vs Memcached 선택 기준은?**

| 요구사항 | Redis | Memcached |
|---------|-------|-----------|
| 자료구조 | String, Set, ZSet, Hash 등 | Key-Value만 |
| 영속성 | RDB/AOF 백업 | 재시작 시 전부 유실 |
| Atomic 연산 | INCR, SADD 등 원자적 | CAS 필요 |
| 분산 락 | 가능 | 불가능 |
| Pub/Sub | 지원 | 미지원 |

결론: 단순 캐싱만 필요하면 Memcached도 괜찮지만, 대부분은 Redis 사용 (더 많은 기능)

---

## 데이터베이스 비교

### RDB vs NoSQL

| 구분 | RDB (MySQL, PostgreSQL) | NoSQL (MongoDB, DynamoDB) |
|------|------------------------|--------------------------|
| 데이터 모델 | 정형, 테이블 (스키마 고정) | 비정형, 유연한 스키마 |
| 트랜잭션 | ACID 보장 | 제한적 (BASE) |
| 확장 | 수직 확장 (Scale-up) | 수평 확장 (Scale-out) |
| 조회 | 복잡한 JOIN | 단순한 Key-Value |
| 사용 | 주문, 결제, 사용자 | 로그, 세션, 캐시 |

---

### MongoDB 특성

**데이터 모델**: Document (JSON-like BSON)

**핵심 특징**:
- 유연한 스키마: 필드 추가/삭제가 자유로움
- Nested Document: 관련 데이터를 하나의 문서에 저장 (JOIN 불필요)
- Sharding: 수평 확장 지원 (데이터를 여러 서버에 분산)

**장점**:
- 빠른 개발 (스키마 변경 쉬움)
- 읽기 성능 우수 (Nested Document로 JOIN 회피)
- 대용량 데이터 처리 (Sharding)

**단점**:
- 트랜잭션 제한적 (4.0부터 Multi-Document 트랜잭션 지원)
- 데이터 중복 가능 (정규화 약함)
- 메모리 사용량 많음

**Aggregation Pipeline**:
```javascript
db.orders.aggregate([
  { $match: { status: "completed" } },
  { $group: { _id: "$userId", total: { $sum: "$amount" } } },
  { $sort: { total: -1 } },
  { $limit: 10 }
])
```

**사용 사례**:
- 로그/이벤트 저장
- 실시간 분석
- 콘텐츠 관리 시스템 (CMS)

---

### DynamoDB 특성

**데이터 모델**: Key-Value, Document

**핵심 특징**:
- Serverless: 서버 관리 불필요
- 자동 확장: 트래픽에 따라 자동 스케일링
- GSI (Global Secondary Index): 다양한 쿼리 패턴 지원
- TTL (Time To Live): 자동 데이터 삭제 (세션 관리에 유용)

**장점**:
- 빠른 조회 (5ms 이하)
- 완전 관리형 (운영 부담 없음)
- 자동 백업 및 복구
- TTL로 만료 데이터 자동 정리

**단점**:
- 쿼리 제한적 (Key 기반 조회만)
- JOIN 불가
- 비용 예측 어려움 (Read/Write 단위 과금)

**GSI (Global Secondary Index)**:
```javascript
// 기본 키: userId (Partition Key)
// GSI: createdAt (Sort Key)
// → 시간순 정렬 조회 가능
const params = {
  IndexName: 'createdAt-index',
  KeyConditionExpression: 'userId = :userId',
  SortKeyConditionExpression: 'createdAt > :date'
};
```

**사용 사례**:
- 세션 저장 (TTL로 자동 만료)
- 지연 발송 시스템 (GSI + TTL)
- 실시간 채팅 메시지

---

### PostgreSQL vs MySQL

| 구분 | PostgreSQL | MySQL |
|------|-----------|-------|
| ACID | 완벽 지원 | 완벽 지원 (InnoDB) |
| 복잡 쿼리 | 우수 (Window Function, CTE) | 보통 |
| JSON | JSONB (인덱싱 가능) | JSON (인덱싱 제한적) |
| 전문 검색 | Full-Text Search 강력 | 기본 수준 |
| 확장성 | Extension 풍부 (PostGIS) | 제한적 |
| 성능 | 복잡 쿼리 빠름 | 단순 쿼리 빠름 |
| 사용 | 분석, 데이터 웨어하우스 | 웹 서비스, 간단한 CRUD |

**PostgreSQL 장점**:
- 복잡한 쿼리 성능 우수
- JSONB로 NoSQL처럼 사용 가능
- Extension으로 기능 확장 (PostGIS, TimescaleDB)

**MySQL 장점**:
- 단순 쿼리 성능 우수
- 레퍼런스 많음 (웹 서비스에서 널리 사용)
- 관리 및 운영 쉬움

---

### 실무 조합 예시

**일반적인 웹 서비스**:
```
MySQL (메인 DB) → 사용자, 주문, 결제
Redis (캐싱) → 세션, 조회수
DynamoDB (세션) → 로그인 세션 (TTL 자동 만료)
```

**대용량 로그 처리**:
```
MongoDB (로그 저장) → Aggregation Pipeline으로 분석
Elasticsearch (검색) → 로그 검색
```

**IoT 서비스**:
```
MySQL (메타 데이터) → 기기 정보, 사용자
DynamoDB (센서 데이터) → 빠른 쓰기, TTL로 오래된 데이터 삭제
Redis (실시간 상태) → 기기 온/오프 상태
```

---

### 면접 질문

**Q1. MongoDB vs DynamoDB 차이는?**
→ MongoDB: Document 모델, Aggregation 강력, Sharding으로 확장
→ DynamoDB: Key-Value, Serverless, GSI + TTL 조합 유용

**Q2. PostgreSQL vs MySQL 선택 기준은?**
→ PostgreSQL: 복잡한 쿼리, 분석, JSONB 활용
→ MySQL: 단순 CRUD, 웹 서비스, 레퍼런스 풍부

**Q3. NoSQL을 언제 사용하나요?**
→ 스키마 변경 빈번, 수평 확장 필요, JOIN 불필요, 단순 Key-Value 조회

---

## 핵심 체크리스트

- 인덱스: B+Tree 장점, 복합 인덱스 Left-Most, 커버링 인덱스, EXPLAIN
- 트랜잭션: ACID, 격리 수준 4가지, REQUIRED vs REQUIRES_NEW, readOnly
- 락: 낙관적 vs 비관적 선택 기준, Deadlock 해결, Next-Key Lock
- 최적화: EXPLAIN 컬럼 (type, key, rows, Extra), 인덱스 못 타는 경우
- 리플리케이션: Master-Slave 구조, Replication Lag 처리
- CQRS: Read/Write 분리, Eventual Consistency, 사용 시나리오
- 대용량 처리: DTO Projection, Cursor 페이지네이션, Batch Insert, 파티셔닝 vs 샤딩
- Redis: 싱글 스레드 원리, 분산 락, 자료구조별 활용
- Connection Pool: HikariCP 설정, 타임아웃 종류
