# 인프라

---

## CI/CD (지속적 통합/지속적 배포)

| 구분 | 설명 |
|------|------|
| CI (지속적 통합) | 개발자가 작업한 코드를 주기적으로 메인에 병합하여 자동으로 빌드와 테스트를 수행함으로써 소프트웨어의 품질을 유지하는 과정 |
| CD (지속적 배포) | CI 과정을 통과한 코드를 자동으로 운영 환경에 배포하여 사용자에게 제공하는 과정 |

---

## Docker

### Docker vs VM

| 구분 | Docker | VM |
|------|--------|-----|
| 정의 | 컨테이너화된 애플리케이션을 생성, 배포, 실행하기 위한 오픈 소스 플랫폼 | 완전히 독립된 가상 환경을 제공하며 자체 OS를 실행할 수 있는 기술 |
| 특징 | 애플리케이션과 그 의존성을 컨테이너 안에 패키징, 환경에 구애받지 않고 실행 가능, 시스템 자원을 효율적으로 사용 | 각 가상 머신은 완전한 게스트 OS를 포함, 다양한 OS 환경을 하나의 서버에서 실행 가능 |
| 이점 | 배포의 효율성과 이식성 향상, VM보다 빠르고 효율적인 리소스 사용(호스트 OS의 커널 공유) | 각 가상 머신은 독립적으로 실행되며, 자원 할당에 있어 무겁고 느릴 수 있음에도 불구하고 완전히 격리된 환경 제공 |

### Docker 핵심 개념

| 개념 | 설명 |
|------|------|
| 이미지 | 컨테이너 실행에 필요한 파일과 설정값을 포함한 템플릿 |
| 컨테이너 | 이미지를 실행한 상태, 애플리케이션의 격리된 실행 환경 |
| Dockerfile | 이미지 생성을 위한 스크립트 파일 |
| 레지스트리 | 이미지를 저장하고 공유하는 저장소 (Docker Hub, ECR 등) |
| 볼륨 | 데이터 영구 저장을 위한 메커니즘 |
| 네트워크 | 컨테이너 간 통신을 위한 가상 네트워크 |

### Dockerfile 예시

```dockerfile
# 베이스 이미지
FROM openjdk:11-jre-slim

# 작업 디렉토리
WORKDIR /app

# JAR 파일 복사
COPY target/app.jar app.jar

# 실행 명령
CMD ["java", "-jar", "app.jar"]
```

### 컨테이너화가 중요한 이유

- 애플리케이션을 격리된 환경에서 실행 가능
- 배포, 확장성과, 이식성 개선
- 환경에 구애받지 않는 일관된 실행 환경 제공

---

## Kubernetes

### 핵심 개념

| 개념 | 설명 |
|------|------|
| 정의 | 도커를 통해 구동되는 컨테이너를 관리하는 시스템. 컨테이너 오케스트레이션 툴 |
| 기능 | 컨테이너화된 애플리케이션의 배포, 확장 및 관리를 자동화 |

### 핵심 구성요소

| 구성요소 | 설명 |
|----------|------|
| Pod | 가장 작은 배포 단위, 하나 이상의 컨테이너를 포함 |
| Service | Pod들에 대한 네트워크 접근을 제공하는 추상화 |
| Deployment | Pod의 생성과 관리를 담당하는 컨트롤러 |
| ConfigMap | 설정 데이터를 저장하는 오브젝트 |
| Secret | 민감한 정보(비밀번호, 토큰)를 저장 |
| Ingress | 외부에서 클러스터 내부로의 HTTP/HTTPS 라우팅 |

### 컨테이너 오케스트레이션

- 컨테이너 배포, 관리, 확장, 네트워킹을 자동화하는 프로세스로 쿠버네티스와 같은 도구를 사용
- 대규모의 컨테이너화된 애플리케이션을 효율적으로 관리

---

## AWS 핵심 서비스

### 주요 서비스 개요

| 서비스 | 설명 |
|--------|------|
| EC2 | 가상 서버 인스턴스 제공 |
| RDS | 관리형 관계형 데이터베이스 서비스 |
| S3 | 객체 스토리지 서비스 |
| Lambda | 서버리스 컴퓨팅 서비스 |
| ELB | 로드 밸런서 서비스 |
| CloudWatch | 모니터링 및 관찰 서비스 |
| VPC | 가상 사설 클라우드 |
| IAM | 권한 및 액세스 관리 |

---

### EC2 (Elastic Compute Cloud)

**가상 서버를 빌려 쓰는 서비스**
- 클릭 몇 번으로 서버 생성/삭제
- 필요한 만큼만 비용 지불
- 다양한 인스턴스 타입 (CPU, 메모리 조합)

**주요 용어**

```
인스턴스 (Instance): 가상 서버 1대
- t2.micro: CPU 1개, RAM 1GB (무료 티어)
- t3.medium: CPU 2개, RAM 4GB
- c5.large: CPU 2개, RAM 4GB (CPU 최적화)

AMI (Amazon Machine Image):
- 서버 복사본 (OS + 설치된 프로그램)
- 예: Ubuntu 22.04, Amazon Linux 2

보안 그룹 (Security Group):
- 방화벽 (어떤 포트를 열 것인가)
- 예: 포트 80(HTTP), 443(HTTPS), 22(SSH)
```

---

### ELB (Elastic Load Balancer)

**트래픽을 여러 서버에 분산시키는 교통정리 역할**

```
사용자 요청
    ↓
  ELB (로드 밸런서)
    ↓
 ┌─────┼─────┐
 ↓     ↓     ↓
EC2-1 EC2-2 EC2-3
```

**주요 타입**

| 타입 | 설명 | 사용 사례 |
|------|------|-----------|
| ALB (Application Load Balancer) | HTTP/HTTPS 트래픽 처리, URL 경로별 라우팅 | /api → 서버 A, /admin → 서버 B |
| NLB (Network Load Balancer) | TCP/UDP 트래픽 처리, 초고속 처리 (수백만 요청/초) | 게임 서버, 실시간 통신 |

**헬스 체크 (Health Check)**

```
ELB가 주기적으로 서버 상태 확인:
- 매 30초마다 GET /health 요청
- 200 OK 응답 → 정상
- 5XX 에러 또는 무응답 → 비정상

비정상 서버는 트래픽 분배에서 제외
→ 서버 1대 죽어도 서비스 중단 없음
```

**Auto Scaling 활용 예시**

```
평소 트래픽:
- 일 평균 사용자 1만 명
- EC2 2대로 충분

프로모션 기간:
- 트래픽 5배 증가
- EC2 10대로 늘림 (Auto Scaling)
- ELB가 자동으로 10대에 분산

효과:
- 서버 다운 없이 프로모션 성공
- 프로모션 끝나면 다시 2대로 축소 → 비용 절감
```

---

### RDS (Relational Database Service)

**관리형 데이터베이스 서비스**
- MySQL, PostgreSQL, MariaDB 등 지원
- 백업, 패치, 모니터링 자동화
- 직접 DB 서버 관리할 필요 없음

**1. 자동 백업**

```
매일 자동 스냅샷:
- 오전 3시에 DB 전체 백업
- 최대 35일 보관
- 언제든 특정 시점으로 복구 가능

Point-in-Time Recovery:
- "2024-11-10 14:30:00" 시점으로 복구
- 예: 오후 2시에 데이터 날렸다면 1시 59분으로 복구
```

**2. Read Replica (읽기 전용 복제본)**

```
Master DB (읽기/쓰기)
    ↓ (복제)
Read Replica (읽기 전용)

장점:
- 조회 쿼리는 Read Replica로 분산
- Master DB 부하 감소
- 쓰기(INSERT, UPDATE)는 Master에만

활용 예시:
- Master: 결제, 구독 데이터 저장 (쓰기)
- Replica: 대시보드 통계, 목록 조회 (읽기)
```

**3. Multi-AZ (다중 가용 영역)**

```
Primary DB (서울 리전)
    ↓ (동기 복제)
Standby DB (서울 리전 다른 데이터센터)

Primary 죽으면:
- 1-2분 내 Standby가 Primary로 자동 승격
- 애플리케이션은 재시작 불필요
- 서비스 중단 최소화
```

---

### CloudWatch

**AWS 리소스 모니터링 도구**
- CPU, 메모리, 디스크 사용률 추적
- 로그 수집 및 검색
- 임계값 초과 시 알람

**메트릭 모니터링**

```
EC2 메트릭:
- CPU 사용률: 80% 이상 → 알람
- 네트워크 In/Out: 트래픽 모니터링
- 디스크 읽기/쓰기: I/O 병목 확인

RDS 메트릭:
- DB 연결 수: 최대 100개 제한
- 쿼리 응답 시간: 평균 200ms
- 스토리지 용량: 80% 이상 → 확장 필요
```

**로그 수집 (CloudWatch Logs)**

```
애플리케이션 로그:
- Spring Boot 로그를 CloudWatch로 전송
- 에러 로그 검색: "ERROR" 키워드로 필터링
- 특정 시간대 로그 조회

예시:
2024-11-11 14:30:25 ERROR [payment] 결제 실패: 카드 승인 거부
2024-11-11 14:31:10 ERROR [payment] 결제 실패: 타임아웃

→ 결제 시스템 장애 발견 → 즉시 조치
```

**알람 (CloudWatch Alarms)**

```
알람 설정 예시:
- CPU 사용률 > 80% (5분간 지속) → SNS 알림
- DB 연결 수 > 90개 → 이메일 발송
- 에러 로그 10건/분 → Slack 알림

대응:
- 자동: Auto Scaling으로 EC2 추가
- 수동: 개발자가 알림 받고 조치
```

---

### S3 (Simple Storage Service)

**무제한 파일 저장소**
- 사진, 동영상, 정적 파일 저장
- 저렴한 비용 (GB당 월 $0.023)
- 99.999999999% 내구성 (데이터 손실 거의 없음)

**주요 용어**

```
버킷 (Bucket):
- 파일을 담는 최상위 컨테이너
- 예: my-app-user-images

객체 (Object):
- 버킷에 저장된 파일
- 최대 5TB

키 (Key):
- 파일 경로
- 예: users/12345/profile.jpg
```

**실무 활용 예시**

```
사용자 프로필 이미지:
1. 사용자가 이미지 업로드
2. Spring Boot에서 S3로 전송
3. S3 URL 반환: https://my-app.s3.ap-northeast-2.amazonaws.com/users/12345/profile.jpg
4. DB에는 URL만 저장 (이미지 파일은 S3에)

장점:
- DB 용량 절약
- 이미지 로딩 빠름 (CDN 연동 가능)
- 스토리지 무제한
```

---

## Kafka

### 핵심 개념

**Kafka란?**
- 정의: 대규모 데이터를 처리할 수 있는 분산 메시지 스트리밍 플랫폼
- 역할: 비동기적으로 데이터를 처리하는 메시지 큐 시스템
- 특징: 높은 처리량, 실시간 데이터 처리, 데이터 영속성 보장

**메시지 큐의 장점**
- 비동기 처리: 프로듀서와 컨슈머의 속도 차이 해결
- 시스템 분리: 서비스 간 느슨한 결합
- 확장성: 독립적인 확장 가능
- 내결함성: 메시지 손실 방지

---

### Kafka 아키텍처

**기본 구성 요소**
- Producer: 메시지를 생산하여 토픽에 전달하는 주체
- Consumer: 토픽에서 메시지를 가져와 처리하는 주체
- Topic: 메시지를 구분하는 카테고리
- Broker: 메시지를 저장하고 클라이언트 요청을 처리 (포트 9092)
- Controller: 클러스터 상태를 관리하는 특별한 브로커 (포트 9093)

**Partition (파티션)**
- 정의: 토픽을 여러 개로 나눠 병렬 처리를 가능하게 하는 단위
- 특징:
  - 각 토픽은 1개 이상의 파티션으로 구성
  - 파티션 내에서만 메시지 순서 보장
  - 하나의 파티션은 하나의 컨슈머에게만 할당 (동일 그룹 내)
  - 파티션 수는 늘릴 수만 있고 줄일 수 없음

**메시지 분배 방식**
- 키 없는 메시지: 스티키 파티셔닝 (배치 단위로 파티션 할당)
- 키 있는 메시지: 키의 해시값 기반으로 파티션 결정 (같은 키 = 같은 파티션)

---

### Consumer Group & Offset

**Consumer Group**
- 정의: 하나 이상의 컨슈머로 구성된 그룹
- 목적: 메시지 중복 처리 방지 및 처리 상태 관리
- 특징: 그룹 단위로 오프셋 관리

**Offset**
- 정의: 컨슈머 그룹이 어디까지 메시지를 읽었는지 기록하는 번호
- 특징:
  - 0부터 시작
  - 컨슈머 그룹 단위로 관리
  - current-offset = 다음에 읽을 메시지 번호

---

### 병렬 처리와 성능 최적화

**병렬 처리 방법**
1. 컨슈머 수 증가: 파티션 수만큼 컨슈머 추가
2. 멀티 스레드 활용: `concurrency` 설정으로 단일 컨슈머의 처리 능력 향상

**적정 파티션 수 계산**
```
프로듀서 메시지 생산량 <= (컨슈머 처리량 x 파티션 수)
```

**Consumer Lag 모니터링**
- 정의: 아직 처리하지 못한 메시지 수
- 발생 원인: 프로듀서 생산량 > 컨슈머 처리량
- 해결 방법:
  - 파티션 수 증가
  - 컨슈머 수 증가
  - 컨슈머 처리 성능 개선

---

### 고가용성 (High Availability)

**클러스터 구성**
- Node: Kafka가 설치된 서버 단위
- Cluster: 여러 노드가 하나의 시스템처럼 동작
- 최소 구성: 3대 이상의 노드 권장

**Replication (복제)**
- 목적: 데이터 안정성과 가용성 보장
- 구성:
  - Leader Partition: 읽기/쓰기 담당 (원본)
  - Follower Partition: Leader 복제본, 장애 시 승격
  - ISR (In-Sync Replica): 완전히 동기화된 복제본 집합

**메시지 처리 확인 방식**

| 설정 | 설명 | 안정성 |
|------|------|--------|
| acks=0 | 확인 없이 전송 (Fire and Forget) | 낮음 |
| acks=1 | Leader 파티션만 확인 | 보통 |
| acks=-1/all | 모든 ISR 확인 | 가장 안전 |

**Offset Commit (컨슈머 확인)**

자동 커밋:
```properties
enable.auto.commit=true
auto.commit.interval.ms=5000  # 5초마다 자동 커밋
```

수동 커밋:
```java
@KafkaListener(topics = "my-topic")
public void listen(String message, Acknowledgment acknowledgment) {
    processMessage(message);  // 메시지 처리
    acknowledgment.acknowledge();  // 처리 성공 시 offset 커밋
}
```

---

### 장애 처리 전략

**Retry (재시도)**
```java
@RetryableTopic(
    attempts = "5",  // 최초 시도 포함 5번
    backoff = @Backoff(delay = 1000, multiplier = 2),  // 지수 백오프
    dltTopicSuffix = ".dlt"
)
```

**DLT (Dead Letter Topic)**
- 정의: 재시도 실패한 메시지를 보관하는 특별한 토픽
- 특징:
  - 원본 메시지는 유지됨
  - 실패 메시지의 복사본 1개만 저장
  - 토픽 단위로 자동 생성 (email.send → email.send.dlt)

---

### 장애 시나리오

**1. Leader Election (리더 선출)**

발생 시점: Broker/Node 장애 시 자동 발생

```
Before: 정상 상태
    Node 1              Node 2              Node 3
┌──────────┐        ┌──────────┐        ┌──────────┐
│  P0 (L)  │───────>│  P0 (F)  │───────>│  P0 (F)  │
├──────────┤        ├──────────┤        ├──────────┤
│  P1 (F)  │<───────│  P1 (L)  │───────>│  P1 (F)  │
└──────────┘        └──────────┘        └──────────┘

After: Node 1 장애 발생
    Node 1              Node 2              Node 3
┌──────────┐        ┌──────────┐        ┌──────────┐
│   죽음    │        │  P0 (L)  │<───────│  P0 (F)  │
│          │        │ Leader!  │        │          │
├──────────┤        ├──────────┤        ├──────────┤
│   죽음    │        │  P1 (L)  │───────>│  P1 (F)  │
└──────────┘        └──────────┘        └──────────┘

자동 복구:
- Node 2의 P0 Follower가 Leader로 승격
- Producer/Consumer가 자동으로 새 Leader(Node 2) 찾아감
- 서비스 중단 없음

문제점:
- P0 복제본: 3개 → 2개로 감소
- Node 2도 죽으면 P0 완전 유실 위험
- 운영자가 수동으로 복제본 재생성 필요
```

**2. Consumer Rebalancing (컨슈머 리밸런싱)**

발생 시점: Consumer 추가/제거 시 자동 발생

```
Before: Consumer 2개
Topic: user-events
  ┌────┐  ┌────┐  ┌────┐
  │ P0 │  │ P1 │  │ P2 │
  └────┘  └────┘  └────┘
     │       │       │
     └───┬───┘       │
         ▼           ▼
    Consumer A   Consumer B
    (P0, P1)      (P2)

After: Consumer C 추가
  ┌────┐  ┌────┐  ┌────┐
  │ P0 │  │ P1 │  │ P2 │
  └────┘  └────┘  └────┘
     │       │       │
     ▼       ▼       ▼
   Con A   Con B   Con C
   (P0)    (P1)    (P2)

- 파티션을 컨슈머들에게 재배분
- 부하 균등 분산
- 리밸런싱 중 잠시 메시지 처리 중단
```

---

### 주요 CLI 명령어

**토픽 관리**
```bash
# 토픽 생성
kafka-topics.sh --create --topic [name] --partitions 3 --replication-factor 2

# 토픽 조회
kafka-topics.sh --list
kafka-topics.sh --describe --topic [name]

# 파티션 수 변경
kafka-topics.sh --alter --topic [name] --partitions 5
```

**메시지 관리**
```bash
# 메시지 발행
kafka-console-producer.sh --topic [name]

# 메시지 소비
kafka-console-consumer.sh --topic [name] --from-beginning --group [group-name]
```

**Consumer Group 관리**
```bash
# 그룹 목록 조회
kafka-consumer-groups.sh --list

# 그룹 상세 정보 (Lag 확인)
kafka-consumer-groups.sh --describe --group [group-name]
```

---

### 면접 질문

**Q1. Kafka를 사용하는 이유는?**
- 대용량 실시간 데이터 처리
- 시스템 간 비동기 통신
- 메시지 영속성과 재처리 가능

**Q2. 파티션과 컨슈머 그룹의 관계는?**
- 하나의 파티션은 그룹 내 하나의 컨슈머만 처리
- 파티션 수 >= 컨슈머 수가 이상적

**Q3. 메시지 순서 보장은 어떻게?**
- 파티션 단위로만 순서 보장
- 같은 키 사용하여 같은 파티션으로 라우팅

**Q4. 장애 발생 시 데이터 손실을 방지하려면?**
- Replication Factor 설정 (2-3)
- acks=all 설정
- min.insync.replicas 설정

**Q5. Consumer Lag가 발생하면?**
- 파티션/컨슈머 수 증가
- 처리 로직 최적화
- 배치 처리 도입

**Q6. Kafka vs RabbitMQ 선택 기준은?**

| 요구사항 | Kafka | RabbitMQ |
|---------|-------|----------|
| 메시지 재처리 | Offset 조정으로 재처리 | 읽으면 삭제됨 |
| 처리량 | 초당 수만~수십만 TPS | 상대적으로 낮음 |
| 메시지 순서 | 파티션 단위 보장 | 큐 단위만 보장 |
| 메시지 영속성 | 설정 기간 동안 보관 | 읽으면 삭제 |
| 라우팅 | 단순 Pub/Sub | Exchange 기반 유연한 라우팅 |

선택 기준: 높은 처리량 + 메시지 재처리가 필요하면 Kafka, 복잡한 라우팅이 필요하면 RabbitMQ

---

## 마이크로서비스 아키텍처

| 개념 | 설명 |
|------|------|
| 정의 | 애플리케이션을 작고 독립적인 서비스들로 분해하는 아키텍처 패턴 |
| 장점 | 독립적 배포, 기술 스택 다양성, 장애 격리, 확장성 |
| 단점 | 분산 시스템 복잡성, 네트워크 지연, 데이터 일관성 문제 |
| 패턴 | API Gateway, Service Discovery, Circuit Breaker, CQRS |

---

## APM (Application Performance Monitoring)

**목적 및 주요 도구**
- 목적: 애플리케이션 성능 및 장애 모니터링
- 주요 도구:
  - 제니퍼: 국산 APM 솔루션
  - 스카우터: 오픈소스 APM
  - Datadog: 클라우드 모니터링
  - New Relic: APM 및 인프라 모니터링

**모니터링 대상**
- DB 응답 시간
- JVM 상태 (메모리, GC)
- 트랜잭션 성능
- 에러율 및 처리량

---

## 부하분산

### L4 스위치
- IP/포트 기반 부하분산
- 세션 지속성 제공
- 헬스체크 기능
- 알고리즘: Round Robin, Least Connection, Weighted

### GSLB (Global Server Load Balancing)
- DNS 기반 글로벌 부하분산
- 사용자 위치 기반 최적 서버 선택

### CDN (Content Delivery Network)
- 전 세계 분산된 엣지 서버에서 컨텐츠 제공
- CDN vs S3: CDN은 전송 최적화, S3는 데이터 저장
- 동기화: Push/Pull/Hybrid 방식

---

## 클라우드 서비스 모델

| 구분 | IaaS | PaaS | SaaS |
|------|------|------|------|
| 정의 | 클라우드가 인프라만 제공 | 클라우드가 인프라와 필요한 서비스를 제공 | 완전한 서비스를 클라우드에서 제공받아 사용 |
| 예시 | AWS EC2 | Heroku, Google App Engine | Google Docs, Salesforce |
| 이점 | 사용자가 OS와 애플리케이션을 직접 설치, 유연한 환경 제공 | 개발자가 애플리케이션 개발에만 집중, 관리가 용이 | 소프트웨어 설치 및 유지보수 필요 없음, 쉬운 접근 |

---

## 온프레미스 → 클라우드 전환

### 클라우드 장점
- 확장성: 트래픽 증가 시 자동 스케일링
- 비용 효율성: 사용한 만큼만 과금, 초기 투자비용 절약
- 가용성: 멀티 리전, 자동 백업/복구
- 관리 편의성: 인프라 관리 부담 감소

### 클라우드 단점
- 보안 우려: 데이터 외부 저장, 클라우드 업체 의존
- 네트워크 의존성: 인터넷 연결 필수, 지연 시간
- 벤더 락인: 특정 클라우드 업체 종속성
- 컴플라이언스: 규제 요구사항 충족 어려움

### 전환 시 고려사항
- 데이터 마이그레이션 계획 (다운타임 최소화)
- 보안 정책 재수립
- TCO(Total Cost of Ownership) 계산
- 직원 교육

---

## Redis

### 핵심 개념

**Redis란?**
- 인메모리 Key-Value NoSQL 데이터베이스
- 메모리 기반으로 매우 빠른 성능 (O(1) 시간 복잡도)
- 싱글 스레드 -> 동시성 이슈 없음

**주요 사용처**
- 캐싱 (조회 성능 향상)
- 세션/인증 관리 (Refresh Token 저장)
- 재고 관리, 좋아요 수 등 동시성 제어
- 실시간 순위/랭킹

---

### 자료구조 & 활용

| 자료구조 | 특징 | 활용 예시 | 주요 명령어 |
|---------|------|----------|------------|
| String | 가장 기본적인 key-value | 캐싱, 토큰 저장, 조회수 | SET, GET, INCR, DECR |
| List | Deque (양방향 큐) | 최근 방문 페이지 (중복 허용) | LPUSH, RPUSH, LRANGE |
| Set | 중복X, 순서X | 좋아요 (중복 방지), 일 방문자 수 | SADD, SMEMBERS, SCARD |
| ZSet | 중복X, score 기준 정렬 | 최근 본 상품(중복X), 실시간 랭킹 | ZADD, ZRANGE, ZREVRANGE |
| Hash | value가 Map 형태 | 자주 변경되는 객체 캐싱 | HSET, HGET, HGETALL |

**선택 기준**
- String vs Hash: JSON 문자열 전체 수정 vs 특정 필드만 수정 -> Hash가 유리
- List vs ZSet: 중복 허용 vs 중복 제거 + 정렬

---

### 서버 구성

**Replication (복제)**
- Master(쓰기) + Slave(읽기) 구조
- 읽기 성능 향상, 하지만 용량 한계 존재 (마스터 메모리 제한)

**Cluster (클러스터)**
- 샤딩 + 고가용성 자동 관리
- 16,384개 Hash Slot 사용
- 마스터 장애 시 슬레이브가 자동 승격
- 서버 추가 시 슬롯 자동 재분배

| 구분 | Replication | Cluster |
|------|-------------|---------|
| 데이터 저장 | 전체 복제 | 분산 샤딩 |
| 용량 한계 | Master 메모리 크기 | 노드 추가로 확장 |
| Failover | Sentinel 필요 | 자동 |
| 최소 노드 | 1 Master + 1 Slave | 3 Master + 3 Slave |
| 쓰기 분산 | X (단일 Master) | O (여러 Master) |

---

### 싱글 스레드 동작 원리

**핵심**: I/O Multiplexing + Event Loop

Redis는 스레드가 1개지만, 여러 클라이언트 연결을 동시에 감시하고 준비된 요청을 빠르게 순차 처리합니다.

```
[클라이언트 A] GET user:1     ──┐
[클라이언트 B] INCR counter   ──┤→ [epoll이 감시] → 준비된 요청 감지
[클라이언트 C] SET key value  ──┘

[Redis 싱글 스레드 Event Loop]
1. A의 GET 처리 (0.01ms) → 응답
2. B의 INCR 처리 (0.01ms) → 응답
3. C의 SET 처리 (0.01ms) → 응답

총 소요: 0.03ms
```

**싱글 스레드의 장점**
- 락 오버헤드 없음
- 컨텍스트 스위칭 없음
- Atomic 보장 (INCR 같은 명령어가 중간에 끊기지 않음)

---

### 분산 락

**분산 락이란?**
여러 서버(인스턴스)가 동시에 같은 자원에 접근할 때, 한 번에 하나의 서버만 작업할 수 있도록 제어하는 메커니즘

| 구분 | 뮤텍스/세마포어 | 분산 락 |
|------|---------------|---------|
| 적용 범위 | 단일 서버 내 멀티 스레드 | 여러 서버 간 |
| 구현 위치 | 메모리 (OS) | Redis/DB |
| 예시 | synchronized, Semaphore(3) | Redisson Lock |

**사용 사례**
- 재고 차감 (동시 구매)
- 결제 처리 (중복 결제 방지)
- 쿠폰 발급 (선착순 제한)
- 좌석 예약 (중복 예약 방지)

**기본 구현: SET NX EX**
```
SET lock:resource "uuid" NX EX 10
- NX: 키가 없을 때만 설정 (Not eXists) -> Lock 획득
- EX 10: 10초 TTL -> 데드락 방지
```

**Lettuce vs Redisson**

| 구분 | Lettuce | Redisson |
|------|---------|----------|
| 수준 | 낮은 수준 (Redis 명령어 직접) | 높은 수준 (추상화된 객체) |
| Spring Boot | 기본 내장 | 별도 의존성 |
| 분산 락 | 직접 구현 필요 | 내장 (getLock) |
| 사용 | 단순 캐싱 | 분산 락, 세마포어 등 |

**Redisson 핵심 기능**
1. Lua 스크립트 자동 사용: Lock 획득/해제를 원자적 처리
2. Watch Dog: 작업이 오래 걸리면 TTL 자동 연장 (30초마다)
3. 재시도 로직 내장: Pub/Sub으로 Lock 해제 감지

---

### Redis 영속성

**문제**: Redis는 인메모리 -> 서버 재시작 시 데이터 날아감

**RDB (스냅샷)**
- 특정 시점의 메모리 전체를 디스크에 저장
- 파일 크기 작음, 복구 빠름
- 단점: 마지막 스냅샷 이후 변경 손실

**AOF (Append Only File)**
- 모든 쓰기 명령어를 로그 파일에 추가 기록
- 데이터 유실 최소화 (everysec 사용 시 최대 1초치만 손실)
- 단점: 파일 크기 큼, 복구 느림

| 구분 | RDB | AOF |
|------|-----|-----|
| 데이터 유실 | 마지막 스냅샷 이후 손실 | 최대 1초치 손실 |
| 파일 크기 | 작음 | 큼 |
| 복구 속도 | 빠름 | 느림 |
| 용도 | 백업, 재해 복구 | 데이터 보존 중요 |

**실무 권장**
- 캐시 용도: 영속성 비활성화
- 세션 등 중요 데이터: AOF everysec
- 아주 중요한 경우: RDB + AOF 함께 사용

---

### 면접 질문

**Q1. Redis는 왜 빠른가?**
- 인메모리 (디스크 I/O 없음)
- Key-Value 구조 (해시 테이블 O(1))
- 싱글 스레드 (락 오버헤드 없음)

**Q2. 싱글 스레드인데 어떻게 동시 처리?**
- Event Loop + I/O Multiplexing
- 명령어 하나하나가 atomic하게 처리됨

**Q3. Redis vs RDB 선택 기준은?**

| 데이터 특성 | 저장소 | 이유 |
|------------|--------|------|
| 자주 변경되는 데이터 (조회수, 좋아요) | Redis | 동시성 제어 쉬움 (INCR) |
| 일시적 데이터 (인증 토큰, 세션) | Redis | TTL 자동 삭제 |
| 대량 읽기 (상품 목록) | Redis 캐싱 + RDB | 조회 성능 향상 |
| 정합성 중요 (결제 정보) | RDB | 트랜잭션 보장 |
| 복잡한 쿼리 (통계, 집계) | RDB | JOIN, GROUP BY 필요 |

**Q4. Cache-Aside 패턴이란?**
```kotlin
// 1. Redis 조회
val cached = redisTemplate.opsForValue().get("key")
if (cached != null) return cached

// 2. RDB 조회
val data = repository.findById(id)

// 3. Redis 저장 (5분 TTL)
redisTemplate.opsForValue().set("key", data, 5, TimeUnit.MINUTES)
return data
```

---

## 핵심 체크리스트

- Docker: 컨테이너 vs VM 차이, Dockerfile 작성
- Kubernetes: Pod, Service, Deployment 역할
- AWS: EC2, RDS, S3, ELB 각 서비스 용도
- Kafka: 파티션, 오프셋, Consumer Group, Replication
- Redis: 자료구조, 분산 락 (Redisson), 영속성 (RDB/AOF)
- 부하분산: L4/L7 차이, CDN 역할
- 모니터링: CloudWatch, APM 도구
